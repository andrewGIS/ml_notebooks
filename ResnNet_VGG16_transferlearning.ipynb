{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why proballity of object creator is to \"close\" to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandDict={0: 'maskBand',\n",
    " 1: 'B01new',\n",
    " 2: 'B02new',\n",
    " 3: 'B03new',\n",
    " 4: 'B04new',\n",
    " 5: 'B05new',\n",
    " 6: 'B06new',\n",
    " 7: 'B07new',\n",
    " 8: 'B08new',\n",
    " 9: 'B8Anew',\n",
    " 10: 'B09new',\n",
    " 11: 'B10new',\n",
    " 12: 'B11new',\n",
    " 13: 'B12new',\n",
    " 14: 'B01old',\n",
    " 15: 'B02old',\n",
    " 16: 'B03old',\n",
    " 17: 'B04old',\n",
    " 18: 'B05old',\n",
    " 19: 'B06old',\n",
    " 20: 'B07old',\n",
    " 21: 'B08old',\n",
    " 22: 'B8Aold',\n",
    " 23: 'B09old',\n",
    " 24: 'B10old',\n",
    " 25: 'B11old',\n",
    " 26: 'B12old'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, \n",
    "                                        ModelCheckpoint, \n",
    "                                        ReduceLROnPlateau, \n",
    "                                        CSVLogger, \n",
    "                                        TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom data generator for Unet PermForestChange\n",
    "    \n",
    "    Main parameter is unputTiffs - list to path to tiff files\n",
    "    \n",
    "    Sample usage \n",
    "    allTifs = list(glob.glob('../../ds/tiles_256_256_27/*/*.tif'))\n",
    "\n",
    "    validSize = 250\n",
    "    \n",
    "    train_generator = DataGenerator(allTifs[:-validSize],batch_size=batch)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, inputTiffs, batch_size=32, num_classes=2, shuffle=True):\n",
    "        self.inputTiffs = inputTiffs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        #custom augmentation with imgaug lib\n",
    "        self.aug_pipe = iaa.Sequential(\n",
    "            [\n",
    "                iaa.SomeOf((0,1),\n",
    "                [\n",
    "                    #iaa.Add((-30, -10)), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.Multiply((0.8, 1.2)),\n",
    "                    \n",
    "                    # Geometric transfroms\n",
    "                    iaa.Rotate((-45,45)),\n",
    "                    iaa.TranslateX(px=(-20, 20)),\n",
    "                    iaa.TranslateY(px=(-20, 20)),\n",
    "                ]\n",
    "                ),\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputTiffs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        #print (indexes)\n",
    "        batchTifs = [self.inputTiffs[k] for k in indexes]\n",
    "        \n",
    "        X, y = self._get_data(batchTifs)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.inputTiffs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def _get_data(self, batch):\n",
    "        #X = inArray\n",
    "        #y = # logic\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for idx,imagePath in enumerate(batch):\n",
    "            \n",
    "            #print (image)\n",
    "            \n",
    "            # raw image\n",
    "            img = io.imread(imagePath)\n",
    "            \n",
    "            # flip with cv2\n",
    "            #flip = np.random.binomial(1, .5)\n",
    "            #if flip > 0.5:\n",
    "                #img = self.flip(img)\n",
    "            \n",
    "            # aug with imgaug lib\n",
    "            img = self.aug_pipe.augment_image(img)\n",
    "            \n",
    "            # x with features\n",
    "            # channel indexes\n",
    "            # mask - 0 \n",
    "            # NEW\n",
    "            #[\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"]\n",
    "            #[ 1,     2,    3,    4,    5,    6,    7,    8,    9,    10,   11,   12,   13  ]\n",
    "            # OLD\n",
    "            #[\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"]\n",
    "            #[ 14,    15,   16,   17,   18,   19,   20,   21,   22,   23,   24,   25,   26  ]\n",
    "            X.append(np.array(\n",
    "                np.dstack([\n",
    "                    #img[:,:,17],# old red\n",
    "                    #img[:,:,4], # new red\n",
    "                    img[:,:,4]/23779 - img[:,:,17]/28000, # dif\n",
    "                    #img[:,:,8],\n",
    "                    #img[:,:,21],\n",
    "                    img[:,:,8]/24796 - img[:,:,21]/28002,\n",
    "                    #(\n",
    "                    #    (img[:,:,21] - img[:,:,17])/(img[:,:,21] + img[:,:,17])- # old ndvi\n",
    "                    #    (img[:,:,8] - img[:,:,4]) /(img[:,:,8] + img[:,:,4])     # new ndvi\n",
    "                    #   \n",
    "                    #), # ndvi diff\n",
    "                    #img[:,:,13],\n",
    "                    #img[:,:,26],\n",
    "                    img[:,:,13]/28000 - img[:,:,26]/28000,\n",
    "                    \n",
    "                ])).astype('float32'))\n",
    "            \n",
    "            # to one class all changes\n",
    "            y_value = None\n",
    "            if \"_with_object.tif\" in imagePath:\n",
    "                y_value = 1\n",
    "            else :\n",
    "                y_value = 0\n",
    "            \n",
    "            y.append(y_value)\n",
    "            #print(np.array(y).shape)\n",
    "            \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def flip(self,image):\n",
    "        \"\"\"\n",
    "        Random flip image around x, y or both axes\n",
    "        image is np.array\n",
    "        \"\"\"\n",
    "        flipDirection = np.random.randint(-1,1,1)[0]\n",
    "        return cv2.flip(image,flipDirection)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = tf.keras.applications.VGG16(\n",
    "    include_top=False, \n",
    "    input_tensor=None, \n",
    "    input_shape=(256,256,3),\n",
    "    pooling=None, \n",
    "    classes=1000, \n",
    "    classifier_activation='softmax',\n",
    "    weights='./files/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Res net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 19,452,928\n",
      "Non-trainable params: 4,134,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33554688  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 57,142,657\n",
      "Trainable params: 53,007,873\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = tf.keras.applications.ResNet50(weights='./files/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                  include_top=False,\n",
    "                  input_shape=(256, 256, 3))\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers[:100]:\n",
    "    layer.trainable = False\n",
    "conv_base.summary()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "179/179 [==============================] - 266s 1s/step - loss: 1.2461 - acc: 0.5017 - val_loss: 0.8894 - val_acc: 0.5125 - lr: 2.0000e-05\n",
      "Epoch 2/5\n",
      "179/179 [==============================] - 263s 1s/step - loss: 0.8455 - acc: 0.4920 - val_loss: 0.7751 - val_acc: 0.5708 - lr: 2.0000e-05\n",
      "Epoch 3/5\n",
      "179/179 [==============================] - 263s 1s/step - loss: 0.7426 - acc: 0.5003 - val_loss: 0.7331 - val_acc: 0.5708 - lr: 2.0000e-05\n",
      "Epoch 4/5\n",
      "179/179 [==============================] - 262s 1s/step - loss: 0.7356 - acc: 0.5021 - val_loss: 0.6901 - val_acc: 0.5792 - lr: 2.0000e-05\n",
      "Epoch 5/5\n",
      "179/179 [==============================] - 266s 1s/step - loss: 0.7081 - acc: 0.5150 - val_loss: 0.7748 - val_acc: 0.4083 - lr: 2.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4be9e5ccd0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "          ModelCheckpoint(\"files/modelIsObjectOnTile.h5\"),\n",
    "          ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "          CSVLogger(\"files/dataIsObjectOnTile.csv\"),\n",
    "]\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(lr=2e-5)\n",
    "metrics = [\"acc\"]\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\n",
    "\n",
    "batch = 16\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "#train_steps = 3405-100//batch\n",
    "#valid_steps = 100//batch\n",
    "\n",
    "#if len(X_train) % batch != 0:\n",
    "    #train_steps += 1\n",
    "#if len(X_test) % batch != 0:\n",
    "    #valid_steps += 1\n",
    "\n",
    "allTifs = list(glob.glob('../../ds/tiles_256_256_27/*/*.tif'))\n",
    "\n",
    "validSize = 250\n",
    "    \n",
    "train_generator = DataGenerator(allTifs[:-validSize],batch_size=batch)\n",
    "valid_generator = DataGenerator(allTifs[-validSize:],batch_size=batch)\n",
    "\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch=len(allTifs[:-validSize])//batch,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_steps=len(allTifs[-validSize:])//batch,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#testImg = '../../ds/tiles_256_256_27_test/T39VVJ_pair_0.tif_8968_5479_no_object.tif'\n",
    "toPredict = []\n",
    "for imgTiff in glob.glob ('../../ds/tiles_256_256_27_test/*.tif'):\n",
    "    img = io.imread(imgTiff)/65536\n",
    "\n",
    "                #flip = np.random.binomial(1, .5)\n",
    "                #if flip > 0.5:\n",
    "                #    img = cv2.flip(img, 1)\n",
    "\n",
    "                # x with features\n",
    "    toPredict.append( np.array(\n",
    "                    np.dstack([\n",
    "                        img[:,:,4] - img[:,:,17], # dif\n",
    "                        #img[:,:,8],\n",
    "                        #img[:,:,21],\n",
    "                        img[:,:,8] - img[:,:,21],\n",
    "                        #(\n",
    "                        #    (img[:,:,21] - img[:,:,17])/(img[:,:,21] + img[:,:,17])- # old ndvi\n",
    "                        #    (img[:,:,8] - img[:,:,4]) /(img[:,:,8] + img[:,:,4])     # new ndvi\n",
    "                        #    \n",
    "                        #), # ndvi diff\n",
    "                        #img[:,:,13],\n",
    "                        #img[:,:,26],\n",
    "                        img[:,:,13] - img[:,:,26],\n",
    "\n",
    "                ]).astype('float32')))\n",
    "\n",
    "#testPredcition = model.predict(np.array([toPredict]))\n",
    "\n",
    "#display output\n",
    "#fig,axes = plt.subplots(ncols=2,figsize=(15,15))\n",
    "#axes[0].imshow(testPredcition[0].astype('float32'))\n",
    "#axes[1].imshow(img[:,:,0])\n",
    "predictedArray = model.predict(np.array(toPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 1)\n",
      "(286, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print (predictedArray.shape)\n",
    "print (np.array(toPredict).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMaxValues(inTiffMask='../../ds/tiles_256_256_27_test/*.tif'):\n",
    "    # mask - 0 \n",
    "    # NEW\n",
    "    #[\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"]\n",
    "    #[ 1,     2,    3,    4,    5,    6,    7,    8,    9,    10,   11,   12,   13  ]\n",
    "    # OLD\n",
    "    #[\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"]\n",
    "    #[ 14,    15,   16,   17,   18,   19,   20,   21,   22,   23,   24,   25,   26  ]\n",
    "    \n",
    "    maxs = []\n",
    "    for imgTiff in glob.glob(inTiffMask):\n",
    "        img = io.imread(imgTiff)\n",
    "        maxsBandValues = np.max(img.reshape((img.shape[0]*img.shape[1],img.shape[2])),axis=0)\n",
    "        maxs.append(maxsBandValues)\n",
    "    maxs = np.max(np.array(maxs),axis=0)\n",
    "    \n",
    "    for bandIdx in bandsDict.keys():\n",
    "        print(f'{bandIdx} - ({bandsDict[bandIdx]}) max value {maxs[bandIdx]}')\n",
    "#calcMaxValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - (maskBand) max value 4\n",
      "1 - (B01new) max value 10163\n",
      "2 - (B02new) max value 22843\n",
      "3 - (B03new) max value 20625\n",
      "4 - (B04new) max value 23779\n",
      "5 - (B05new) max value 21645\n",
      "6 - (B06new) max value 22797\n",
      "7 - (B07new) max value 23368\n",
      "8 - (B08new) max value 24796\n",
      "9 - (B8Anew) max value 23897\n",
      "10 - (B09new) max value 9759\n",
      "11 - (B10new) max value 1881\n",
      "12 - (B11new) max value 28000\n",
      "13 - (B12new) max value 28000\n",
      "14 - (B01old) max value 10270\n",
      "15 - (B02old) max value 28000\n",
      "16 - (B03old) max value 28000\n",
      "17 - (B04old) max value 28000\n",
      "18 - (B05old) max value 24759\n",
      "19 - (B06old) max value 26785\n",
      "20 - (B07old) max value 27263\n",
      "21 - (B08old) max value 28002\n",
      "22 - (B8Aold) max value 28000\n",
      "23 - (B09old) max value 9110\n",
      "24 - (B10old) max value 1731\n",
      "25 - (B11old) max value 24148\n",
      "26 - (B12old) max value 28000\n"
     ]
    }
   ],
   "source": [
    "calcMaxValues(inTiffMask='../../ds/tiles_256_256_27/*/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6251441 ],\n",
       "       [0.62520385],\n",
       "       [0.62514013],\n",
       "       [0.6251287 ],\n",
       "       [0.62553155],\n",
       "       [0.62516   ],\n",
       "       [0.6252359 ],\n",
       "       [0.62514406],\n",
       "       [0.62521243],\n",
       "       [0.62511957],\n",
       "       [0.6251584 ],\n",
       "       [0.6249953 ],\n",
       "       [0.6252962 ],\n",
       "       [0.6251849 ],\n",
       "       [0.62515223],\n",
       "       [0.6250522 ],\n",
       "       [0.6251418 ],\n",
       "       [0.6252138 ],\n",
       "       [0.6252393 ],\n",
       "       [0.6252299 ],\n",
       "       [0.6252088 ],\n",
       "       [0.62546873],\n",
       "       [0.625134  ],\n",
       "       [0.6252367 ],\n",
       "       [0.62518096],\n",
       "       [0.62517655],\n",
       "       [0.625145  ],\n",
       "       [0.6251684 ],\n",
       "       [0.62518907],\n",
       "       [0.6251509 ],\n",
       "       [0.62513816],\n",
       "       [0.62522376],\n",
       "       [0.6251449 ],\n",
       "       [0.6250989 ],\n",
       "       [0.62516373],\n",
       "       [0.6251414 ],\n",
       "       [0.6251684 ],\n",
       "       [0.6251552 ],\n",
       "       [0.625166  ],\n",
       "       [0.62516654],\n",
       "       [0.62516093],\n",
       "       [0.6251888 ],\n",
       "       [0.6251774 ],\n",
       "       [0.62520087],\n",
       "       [0.6252358 ],\n",
       "       [0.62520945],\n",
       "       [0.62514025],\n",
       "       [0.6252493 ],\n",
       "       [0.6251761 ],\n",
       "       [0.62517554],\n",
       "       [0.6251909 ],\n",
       "       [0.62518656],\n",
       "       [0.6252324 ],\n",
       "       [0.6251738 ],\n",
       "       [0.6251818 ],\n",
       "       [0.62520427],\n",
       "       [0.62523884],\n",
       "       [0.62519574],\n",
       "       [0.6252264 ],\n",
       "       [0.6252562 ],\n",
       "       [0.6251445 ],\n",
       "       [0.6253681 ],\n",
       "       [0.6252481 ],\n",
       "       [0.6251636 ],\n",
       "       [0.625117  ],\n",
       "       [0.6252802 ],\n",
       "       [0.6252542 ],\n",
       "       [0.6251321 ],\n",
       "       [0.62518615],\n",
       "       [0.62517697],\n",
       "       [0.62521344],\n",
       "       [0.625087  ],\n",
       "       [0.6250917 ],\n",
       "       [0.6251441 ],\n",
       "       [0.6251836 ],\n",
       "       [0.62518734],\n",
       "       [0.6251693 ],\n",
       "       [0.6252226 ],\n",
       "       [0.6252627 ],\n",
       "       [0.6251421 ],\n",
       "       [0.62523997],\n",
       "       [0.6253097 ],\n",
       "       [0.6251735 ],\n",
       "       [0.6251696 ],\n",
       "       [0.6251509 ],\n",
       "       [0.6251693 ],\n",
       "       [0.62516975],\n",
       "       [0.6251661 ],\n",
       "       [0.6251586 ],\n",
       "       [0.62515646],\n",
       "       [0.62515754],\n",
       "       [0.6251883 ],\n",
       "       [0.6251756 ],\n",
       "       [0.62519306],\n",
       "       [0.625195  ],\n",
       "       [0.62520283],\n",
       "       [0.6251571 ],\n",
       "       [0.62520975],\n",
       "       [0.6251802 ],\n",
       "       [0.62518376],\n",
       "       [0.6251913 ],\n",
       "       [0.6251269 ],\n",
       "       [0.62498254],\n",
       "       [0.6251447 ],\n",
       "       [0.6252008 ],\n",
       "       [0.6251757 ],\n",
       "       [0.62517387],\n",
       "       [0.6251785 ],\n",
       "       [0.6251819 ],\n",
       "       [0.6251924 ],\n",
       "       [0.62520957],\n",
       "       [0.6252294 ],\n",
       "       [0.6251257 ],\n",
       "       [0.6253574 ],\n",
       "       [0.6251606 ],\n",
       "       [0.62517273],\n",
       "       [0.6251552 ],\n",
       "       [0.62515795],\n",
       "       [0.62518126],\n",
       "       [0.62518823],\n",
       "       [0.62515914],\n",
       "       [0.6251403 ],\n",
       "       [0.6251836 ],\n",
       "       [0.6250805 ],\n",
       "       [0.6251902 ],\n",
       "       [0.62513745],\n",
       "       [0.6251929 ],\n",
       "       [0.6252134 ],\n",
       "       [0.6251729 ],\n",
       "       [0.6251753 ],\n",
       "       [0.62514114],\n",
       "       [0.62521625],\n",
       "       [0.6252132 ],\n",
       "       [0.6252184 ],\n",
       "       [0.62525207],\n",
       "       [0.6253094 ],\n",
       "       [0.6253026 ],\n",
       "       [0.62531114],\n",
       "       [0.6251597 ],\n",
       "       [0.6252289 ],\n",
       "       [0.6252787 ],\n",
       "       [0.6251592 ],\n",
       "       [0.6251537 ],\n",
       "       [0.62514514],\n",
       "       [0.6251676 ],\n",
       "       [0.62517804],\n",
       "       [0.6251783 ],\n",
       "       [0.62515485],\n",
       "       [0.62523526],\n",
       "       [0.62517715],\n",
       "       [0.6249647 ],\n",
       "       [0.62519044],\n",
       "       [0.6250385 ],\n",
       "       [0.62496173],\n",
       "       [0.6249209 ],\n",
       "       [0.62526715],\n",
       "       [0.625173  ],\n",
       "       [0.6251407 ],\n",
       "       [0.6252133 ],\n",
       "       [0.62522393],\n",
       "       [0.62513816],\n",
       "       [0.6251865 ],\n",
       "       [0.62514967],\n",
       "       [0.62516904],\n",
       "       [0.625181  ],\n",
       "       [0.62516564],\n",
       "       [0.6252003 ],\n",
       "       [0.6252118 ],\n",
       "       [0.62530535],\n",
       "       [0.62541693],\n",
       "       [0.62522084],\n",
       "       [0.625318  ],\n",
       "       [0.6251983 ],\n",
       "       [0.62522364],\n",
       "       [0.6251645 ],\n",
       "       [0.6252228 ],\n",
       "       [0.6249922 ],\n",
       "       [0.62522376],\n",
       "       [0.6250999 ],\n",
       "       [0.62504894],\n",
       "       [0.6251701 ],\n",
       "       [0.62516224],\n",
       "       [0.6251238 ],\n",
       "       [0.6251601 ],\n",
       "       [0.62522644],\n",
       "       [0.6252486 ],\n",
       "       [0.6251236 ],\n",
       "       [0.6252034 ],\n",
       "       [0.6251294 ],\n",
       "       [0.62520754],\n",
       "       [0.625156  ],\n",
       "       [0.6251793 ],\n",
       "       [0.6251934 ],\n",
       "       [0.62536573],\n",
       "       [0.62530774],\n",
       "       [0.62522596],\n",
       "       [0.6251372 ],\n",
       "       [0.62518424],\n",
       "       [0.62522435],\n",
       "       [0.6254139 ],\n",
       "       [0.62524766],\n",
       "       [0.62518126],\n",
       "       [0.6251637 ],\n",
       "       [0.6251705 ],\n",
       "       [0.6251239 ],\n",
       "       [0.625164  ],\n",
       "       [0.6250691 ],\n",
       "       [0.62508965],\n",
       "       [0.6251994 ],\n",
       "       [0.62520266],\n",
       "       [0.6251911 ],\n",
       "       [0.62518793],\n",
       "       [0.6251202 ],\n",
       "       [0.6256388 ],\n",
       "       [0.6252326 ],\n",
       "       [0.62517166],\n",
       "       [0.6251993 ],\n",
       "       [0.62523836],\n",
       "       [0.62520444],\n",
       "       [0.62525254],\n",
       "       [0.6251444 ],\n",
       "       [0.62519366],\n",
       "       [0.6251267 ],\n",
       "       [0.6251087 ],\n",
       "       [0.6252162 ],\n",
       "       [0.62524825],\n",
       "       [0.6251571 ],\n",
       "       [0.625038  ],\n",
       "       [0.62516755],\n",
       "       [0.62520576],\n",
       "       [0.62516075],\n",
       "       [0.6252513 ],\n",
       "       [0.62521935],\n",
       "       [0.6251864 ],\n",
       "       [0.62523973],\n",
       "       [0.62523055],\n",
       "       [0.6251042 ],\n",
       "       [0.6251548 ],\n",
       "       [0.6252432 ],\n",
       "       [0.6252656 ],\n",
       "       [0.6251431 ],\n",
       "       [0.62517375],\n",
       "       [0.6251411 ],\n",
       "       [0.6251625 ],\n",
       "       [0.6252992 ],\n",
       "       [0.6251924 ],\n",
       "       [0.6251697 ],\n",
       "       [0.62518114],\n",
       "       [0.6252552 ],\n",
       "       [0.6251928 ],\n",
       "       [0.6251707 ],\n",
       "       [0.6252599 ],\n",
       "       [0.6251409 ],\n",
       "       [0.6251452 ],\n",
       "       [0.62510836],\n",
       "       [0.6251699 ],\n",
       "       [0.6251663 ],\n",
       "       [0.62514734],\n",
       "       [0.62517613],\n",
       "       [0.62516546],\n",
       "       [0.6251745 ],\n",
       "       [0.6251654 ],\n",
       "       [0.62520206],\n",
       "       [0.6251687 ],\n",
       "       [0.6251747 ],\n",
       "       [0.625175  ],\n",
       "       [0.6251224 ],\n",
       "       [0.6252096 ],\n",
       "       [0.6251552 ],\n",
       "       [0.6251044 ],\n",
       "       [0.6251294 ],\n",
       "       [0.6252025 ],\n",
       "       [0.62514496],\n",
       "       [0.62517613],\n",
       "       [0.62514955],\n",
       "       [0.6251993 ],\n",
       "       [0.6252536 ],\n",
       "       [0.6251604 ],\n",
       "       [0.62519515],\n",
       "       [0.62515396],\n",
       "       [0.62520427],\n",
       "       [0.62518877],\n",
       "       [0.6252389 ],\n",
       "       [0.6253213 ],\n",
       "       [0.62514734],\n",
       "       [0.625164  ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-fcd29b13ac76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTifs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_last/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_last/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1087\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_last/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_last/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_called_in_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_last/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_finalize_progbar\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    933\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "testTifs = list(glob.glob('../../ds/tiles_256_256_27_test/*/*.tif'))\n",
    "\n",
    "test_generator = DataGenerator(testTifs,batch_size=16)\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
